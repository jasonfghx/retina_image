{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"xw-PXmInH86U","executionInfo":{"status":"ok","timestamp":1764398389058,"user_tz":-480,"elapsed":15027,"user":{"displayName":"楊翔斌 YANG, SHIANG BIn N07061033","userId":"17781018626510550838"}}},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","from tqdm import tqdm\n","import torch.optim as optim\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Dataset\n","import json\n","import torchvision\n","from torchvision import transforms\n","from torchvision.utils import save_image, make_grid\n","from torch.utils.data import Subset, random_split\n","from glob import glob\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from PIL import Image\n","import pandas as pd\n","import shutil\n","from pycocotools import mask as coco_mask\n","import os\n","from glob import glob\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import cv2\n","import seaborn as sns\n","import numpy as np\n","# from mpl_toolkits.axes_grid import ImageGrid\n","\n","from tqdm.notebook import tqdm\n","import time\n","import random\n","from PIL import Image\n","\n","\n","from sklearn.model_selection import train_test_split\n","from torchvision import transforms\n","import torchvision.transforms.functional as TF\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ucrm-1qQDfiS","outputId":"9ee774bd-c6ae-4646-e11b-f6ae58da7229","executionInfo":{"status":"ok","timestamp":1764398374025,"user_tz":-480,"elapsed":26253,"user":{"displayName":"楊翔斌 YANG, SHIANG BIn N07061033","userId":"17781018626510550838"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'retina_image'...\n","remote: Enumerating objects: 1696, done.\u001b[K\n","remote: Counting objects: 100% (61/61), done.\u001b[K\n","remote: Compressing objects: 100% (61/61), done.\u001b[K\n","remote: Total 1696 (delta 18), reused 0 (delta 0), pack-reused 1635 (from 2)\u001b[K\n","Receiving objects: 100% (1696/1696), 332.51 MiB | 16.92 MiB/s, done.\n","Resolving deltas: 100% (136/136), done.\n","Updating files: 100% (1407/1407), done.\n"]}],"source":["!git clone https://github.com/jasonfghx/retina_image.git"]},{"cell_type":"code","source":["import pandas as pd\n","image=sorted(glob(\"/content/retina_image/s1/images/*\"))\n","mask=sorted(glob(\"/content/retina_image/s1/masks/*\"))"],"metadata":{"id":"-tL0-ztjBY3z","executionInfo":{"status":"ok","timestamp":1764398389073,"user_tz":-480,"elapsed":1,"user":{"displayName":"楊翔斌 YANG, SHIANG BIn N07061033","userId":"17781018626510550838"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["dff = pd.DataFrame({\"image_path\": image,\n","                   \"mask_path\": mask})"],"metadata":{"id":"m6imbcuNIypY","executionInfo":{"status":"ok","timestamp":1764398395002,"user_tz":-480,"elapsed":5,"user":{"displayName":"楊翔斌 YANG, SHIANG BIn N07061033","userId":"17781018626510550838"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"DFajf5MMJs0f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Dataset:\n","    def __init__(self, df,transforms):\n","        self.df = df\n","        self.transforms = transforms\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        image = cv2.imread(self.df.iloc[idx, 0])\n","        mask = cv2.imread(self.df.iloc[idx, 1], cv2.IMREAD_GRAYSCALE)\n","        image = Image.fromarray(image)\n","        mask  = Image.fromarray(mask)\n","        image, mask = self.transforms(image, mask)\n","\n","\n","\n","        return image, mask\n","class ComposeDouble:\n","    def __init__(self, transforms):\n","        self.transforms = transforms\n","\n","    def __call__(self, image, mask):\n","        for t in self.transforms:\n","            image, mask = t(image, mask)\n","        return image, mask\n","class Resize:\n","    def __init__(self, size):\n","        self.size = size  # tuple (H, W)\n","\n","    def __call__(self, image, mask):\n","        image = image.resize(self.size, resample=Image.BILINEAR)  # RGB image 用 BILINEAR\n","        mask  = mask.resize(self.size, resample=Image.NEAREST)    # mask 用 NEAREST 避免插值改變類別\n","        return image, mask\n","\n","\n","\n","class ToTensor:\n","    def __call__(self, image, mask):\n","        # image: PIL Image -> Tensor (C,H,W)\n","        image = TF.to_tensor(image).float()  # (3,H,W)\n","\n","        # mask: PIL Image -> Tensor (1,H,W)\n","        mask = torch.as_tensor(np.array(mask)/255, dtype=torch.float).unsqueeze(0)  # (1,H,W)\n","\n","        return image, mask\n","\n","\n","train_transform = ComposeDouble([\n","    Resize((64, 64)),\n","    ToTensor()\n","])\n","# 上面64可以改成128,256\n","train_df, val_df = train_test_split(dff,  test_size=0.1)\n","train_df = train_df.reset_index(drop=True)\n","val_df = val_df.reset_index(drop=True)\n","\n","train_df, test_df = train_test_split(train_df,  test_size=0.12)\n","train_df = train_df.reset_index(drop=True)\n","\n","print(f\"Train: {train_df.shape} \\nVal: {val_df.shape} \\nTest: {test_df.shape}\")\n","train_dataset = Dataset(train_df,train_transform)\n","train_dataloader = DataLoader(train_dataset, batch_size=32, num_workers=2, shuffle=True)\n","\n","val_dataset = Dataset(val_df,train_transform)\n","val_dataloader = DataLoader(val_dataset, batch_size=2, num_workers=2, shuffle=True)\n","\n","test_dataset = Dataset(test_df,train_transform)\n","test_dataloader = DataLoader(test_dataset, batch_size=26, num_workers=2, shuffle=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sA_wRNyyJ6wW","executionInfo":{"status":"ok","timestamp":1764398423192,"user_tz":-480,"elapsed":24,"user":{"displayName":"楊翔斌 YANG, SHIANG BIn N07061033","userId":"17781018626510550838"}},"outputId":"00e1ad59-961f-42f9-da51-f1e8c7697694"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Train: (73, 2) \n","Val: (10, 2) \n","Test: (10, 2)\n"]}]},{"cell_type":"code","source":["images, masks = next(iter(train_dataloader))\n","(masks.numpy())"],"metadata":{"id":"4N1hud94LXRH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ConvBlock(nn.Module):\n","    def __init__(self, ch_in, ch_out):\n","        super().__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n","            nn.BatchNorm2d(ch_out),\n","            nn.ReLU(inplace=True),\n","\n","            nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n","            nn.BatchNorm2d(ch_out),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","    def forward(self, x):\n","        return self.conv(x)\n","class UpConvBlock(nn.Module):\n","    def __init__(self, ch_in, ch_out):\n","        super().__init__()\n","        self.up = nn.Sequential(\n","                                nn.Upsample(scale_factor=2),\n","                                nn.Conv2d(ch_in, ch_out,\n","                                         kernel_size=3,stride=1,\n","                                         padding=1, bias=True),\n","                                nn.BatchNorm2d(ch_out),\n","                                nn.ReLU(inplace=True),\n","        )\n","\n","    def forward(self, x):\n","        x = x = self.up(x)\n","        return x\n","class AttentionBlock(nn.Module):\n","    def __init__(self, f_g, f_l, f_int):\n","        super().__init__()\n","\n","        self.w_g = nn.Sequential(\n","                                nn.Conv2d(f_g, f_int,\n","                                         kernel_size=1, stride=1,\n","                                         padding=0, bias=True),\n","                                nn.BatchNorm2d(f_int)\n","        )\n","\n","        self.w_x = nn.Sequential(\n","                                nn.Conv2d(f_l, f_int,\n","                                         kernel_size=1, stride=1,\n","                                         padding=0, bias=True),\n","                                nn.BatchNorm2d(f_int)\n","        )\n","\n","        self.psi = nn.Sequential(\n","                                nn.Conv2d(f_int, 1,\n","                                         kernel_size=1, stride=1,\n","                                         padding=0,  bias=True),\n","                                nn.BatchNorm2d(1),\n","                                nn.Sigmoid(),\n","        )\n","\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def forward(self, g, x):\n","        g1 = self.w_g(g)\n","        x1 = self.w_x(x)\n","        psi = self.relu(g1+x1)\n","        psi = self.psi(psi)\n","\n","        return psi*x\n","class AttentionUNet(nn.Module):\n","    def __init__(self, n_classes=1, in_channel=3, out_channel=1):\n","        super().__init__()\n","\n","        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        self.conv1 = ConvBlock(ch_in=in_channel, ch_out=64)\n","        self.conv2 = ConvBlock(ch_in=64, ch_out=128)\n","        self.conv3 = ConvBlock(ch_in=128, ch_out=256)\n","        self.conv4 = ConvBlock(ch_in=256, ch_out=512)\n","        # self.conv5 = ConvBlock(ch_in=512, ch_out=1024)\n","\n","        # self.up5 = UpConvBlock(ch_in=1024, ch_out=512)\n","        # self.att5 = AttentionBlock(f_g=512, f_l=512, f_int=256)\n","        # self.upconv5 = ConvBlock(ch_in=1024, ch_out=512)\n","\n","        self.up4 = UpConvBlock(ch_in=512, ch_out=256)\n","        self.att4 = AttentionBlock(f_g=256, f_l=256, f_int=128)\n","        self.upconv4 = ConvBlock(ch_in=512, ch_out=256)\n","\n","        self.up3 = UpConvBlock(ch_in=256, ch_out=128)\n","        self.att3 = AttentionBlock(f_g=128, f_l=128, f_int=64)\n","        self.upconv3 = ConvBlock(ch_in=256, ch_out=128)\n","\n","        self.up2 = UpConvBlock(ch_in=128, ch_out=64)\n","        self.att2 = AttentionBlock(f_g=64, f_l=64, f_int=32)\n","        self.upconv2 = ConvBlock(ch_in=128, ch_out=64)\n","\n","        self.conv_1x1 = nn.Conv2d(64, out_channel,\n","                                  kernel_size=1, stride=1, padding=0)\n","\n","    def forward(self, x):\n","        # encoder\n","        x1 = self.conv1(x)\n","\n","        x2 = self.maxpool(x1)\n","        x2 = self.conv2(x2)\n","\n","        x3 = self.maxpool(x2)\n","        x3 = self.conv3(x3)\n","\n","        x4 = self.maxpool(x3)\n","        x4 = self.conv4(x4)\n","\n","        # x5 = self.maxpool(x4)\n","        # x5 = self.conv5(x5)\n","\n","        # decoder + concat\n","        # d5 = self.up5(x5)\n","        # x4 = self.att5(g=d5, x=x4)\n","        # d5 = torch.concat((x4, d5), dim=1)\n","        # d5 = self.upconv5(d5)\n","        d4 = self.up4(x4)\n","        x3 = self.att4(g=d4, x=x3)\n","        d4 = torch.concat((x3, d4), dim=1)\n","        d4 = self.upconv4(d4)\n","\n","        # d4 = self.up4(d5)\n","        # x3 = self.att4(g=d4, x=x3)\n","        # d4 = torch.concat((x3, d4), dim=1)\n","        # d4 = self.upconv4(d4)\n","\n","        d3 = self.up3(d4)\n","        x2 = self.att3(g=d3, x=x2)\n","        d3 = torch.concat((x2, d3), dim=1)\n","        d3 = self.upconv3(d3)\n","\n","        d2 = self.up2(d3)\n","        x1 = self.att2(g=d2, x=x1)\n","        d2 = torch.concat((x1, d2), dim=1)\n","        d2 = self.upconv2(d2)\n","\n","        d1 = self.conv_1x1(d2)\n","\n","        return d1\n","\n","\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","attention_unet = AttentionUNet(n_classes=1).to(device)\n"],"metadata":{"id":"JrYH7tuOMs5u","executionInfo":{"status":"ok","timestamp":1764398443167,"user_tz":-480,"elapsed":367,"user":{"displayName":"楊翔斌 YANG, SHIANG BIn N07061033","userId":"17781018626510550838"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def dice_coef_metric(inputs, target):\n","    intersection = 2.0 * (target*inputs).sum()\n","    union = target.sum() + inputs.sum()\n","    if target.sum() == 0 and inputs.sum() == 0:\n","        return 1.0\n","    return intersection/union\n","class DiceLoss(nn.Module):\n","    def __init__(self, weight=None, size_average=True):\n","        super(DiceLoss, self).__init__()\n","\n","    def forward(self, inputs, targets, smooth=1):\n","\n","        #comment out if your model contains a sigmoid or equivalent activation layer\n","        inputs = F.sigmoid(inputs)\n","\n","        #flatten label and prediction tensors\n","        inputs = inputs.view(-1)\n","        targets = targets.view(-1)\n","\n","        intersection = (inputs * targets).sum()\n","        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n","\n","        return 1 - dice"],"metadata":{"id":"m_VGvnSTNqSH","executionInfo":{"status":"ok","timestamp":1764398444944,"user_tz":-480,"elapsed":7,"user":{"displayName":"楊翔斌 YANG, SHIANG BIn N07061033","userId":"17781018626510550838"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def train_model(model, train_loader, val_loader, train_loss, optimizer, lr_scheduler, num_epochs):\n","\n","\n","    loss_history = []\n","    train_history = []\n","    val_history = []\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","\n","        losses = []\n","        train_iou = []\n","\n","        for i_step, (data, target) in enumerate(tqdm(train_loader)):\n","            data = data.to(device)\n","            target = target.to(device)\n","\n","            outputs = model(data)\n","\n","            out_cut = np.copy(outputs.data.cpu().numpy())\n","            out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n","            out_cut[np.nonzero(out_cut >= 0.5)] = 1.0\n","\n","            train_dice = dice_coef_metric(out_cut, target.data.cpu().numpy())\n","\n","            loss = train_loss(outputs, target)\n","\n","            losses.append(loss.item())\n","            train_iou.append(train_dice)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","        val_mean_iou = compute_iou(model, val_loader)\n","\n","        loss_history.append(np.array(losses).mean())\n","        train_history.append(np.array(train_iou).mean())\n","        val_history.append(val_mean_iou)\n","\n","        print(\"Epoch [%d]\" % (epoch))\n","        print(\"Mean loss on train:\", np.array(losses).mean(),\n","              \"\\nMean DICE on train:\", np.array(train_iou).mean(),\n","              \"\\nMean DICE on validation:\", val_mean_iou)\n","\n","    return loss_history, train_history, val_history"],"metadata":{"id":"2LKyojQCN0kW","executionInfo":{"status":"ok","timestamp":1764398563858,"user_tz":-480,"elapsed":42,"user":{"displayName":"楊翔斌 YANG, SHIANG BIn N07061033","userId":"17781018626510550838"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def compute_iou(model, loader, threshold=0.3):\n","    valloss = 0\n","\n","    with torch.no_grad():\n","\n","        for i_step, (data, target) in enumerate(loader):\n","\n","            data = data.to(device)\n","            target = target.to(device)\n","\n","            outputs = model(data)\n","\n","            out_cut = np.copy(outputs.data.cpu().numpy())\n","            out_cut[np.nonzero(out_cut < threshold)] = 0.0\n","            out_cut[np.nonzero(out_cut >= threshold)] = 1.0\n","            picloss = dice_coef_metric(out_cut, target.data.cpu().numpy())\n","            valloss += picloss\n","\n","    return valloss / i_step\n","opt = torch.optim.Adamax(attention_unet.parameters(), lr=1e-3)"],"metadata":{"id":"drZtTHEqN1E-","executionInfo":{"status":"ok","timestamp":1764398565703,"user_tz":-480,"elapsed":13,"user":{"displayName":"楊翔斌 YANG, SHIANG BIn N07061033","userId":"17781018626510550838"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["num_ep = 40\n","aun_lh, aun_th, aun_vh = train_model( attention_unet, train_dataloader, val_dataloader, DiceLoss(), opt, False, num_ep)"],"metadata":{"id":"Hg0_DoWxN3HO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 存檔\n","torch.save(attention_unet, \"attention_unet_full.pt\")"],"metadata":{"id":"v_0NrF94Whok","executionInfo":{"status":"ok","timestamp":1764398670807,"user_tz":-480,"elapsed":125,"user":{"displayName":"楊翔斌 YANG, SHIANG BIn N07061033","userId":"17781018626510550838"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["class ResizeImageOnly:\n","    def __init__(self, size):\n","        self.size = size  # (H, W)\n","\n","    def __call__(self, image):\n","        return image.resize(self.size, resample=Image.BILINEAR)\n","class ToTensorImageOnly:\n","    def __call__(self, image):\n","        image = TF.to_tensor(image).float()  # (3,H,W) and normalized to 0~1\n","        return image\n","class ComposeSingle:\n","    def __init__(self, transforms):\n","        self.transforms = transforms\n","\n","    def __call__(self, image):\n","        for t in self.transforms:\n","            image = t(image)\n","        return image\n","inference_transform = ComposeSingle([\n","    ResizeImageOnly((64, 64)),\n","    ToTensorImageOnly()\n","])\n","img = Image.open('/content/retina_image/s1/images/Stage_1_ROP_2.jpg').convert(\"RGB\")   # 讀檔\n","tensor = inference_transform(img)                 # Resize + ToTensor\n","tensor = tensor.unsqueeze(0)"],"metadata":{"id":"TLSEVXIkZC0C","executionInfo":{"status":"ok","timestamp":1764399339984,"user_tz":-480,"elapsed":50,"user":{"displayName":"楊翔斌 YANG, SHIANG BIn N07061033","userId":"17781018626510550838"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["attention_unet.eval()              # 切成推論模式\n","\n","with torch.no_grad():     # 關掉梯度，避免浪費記憶體與速度\n","    img_tensor = tensor.to(device)\n","\n","    output = attention_unet(img_tensor)      # [B,1,H,W] 或 [B,2,H,W]\n","    prob = torch.sigmoid(output)    # 如果你的最後一層沒有 sigmoid\n","    pred = (prob > 0.5).float()\n"],"metadata":{"id":"RmMKuQxYXs10","executionInfo":{"status":"ok","timestamp":1764399341243,"user_tz":-480,"elapsed":17,"user":{"displayName":"楊翔斌 YANG, SHIANG BIn N07061033","userId":"17781018626510550838"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JnA5JMGgXiDT","executionInfo":{"status":"ok","timestamp":1764399235719,"user_tz":-480,"elapsed":20,"user":{"displayName":"楊翔斌 YANG, SHIANG BIn N07061033","userId":"17781018626510550838"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["plt.imshow(pred.cpu().numpy()[0][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":449},"id":"MIVtUW5MXnmE","executionInfo":{"status":"ok","timestamp":1764399342669,"user_tz":-480,"elapsed":130,"user":{"displayName":"楊翔斌 YANG, SHIANG BIn N07061033","userId":"17781018626510550838"}},"outputId":"bda2eab7-9871-426d-d13e-42d6141ea5f4"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7e7140a4c830>"]},"metadata":{},"execution_count":33},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAaAAAAGfCAYAAAAZGgYhAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAHYNJREFUeJzt3XFs1PX9x/FXa9ujUnqlFa7taFmNaEEsYoFyAzcHnQ0/Y8qoDg1mzBGJrKDQLWoXBbc4yzQK4qCoc6CZrJMlgLgfMFOlRlcqVIkoWwVt1s5yx1zsXenstdDP7w9/3jxp1WuvfHrH85F8E/r9fu/6/oSkz3zbb7+NM8YYAQBwjsXbHgAAcH4iQAAAKwgQAMAKAgQAsIIAAQCsIEAAACsIEADACgIEALCCAAEArCBAAAArEobqjTdu3KiHH35YHo9HU6ZM0eOPP64ZM2Z85et6e3vV1tamUaNGKS4ubqjGAwAMEWOMOjo6lJ2drfj4L7nOMUOgpqbGJCUlmd/97nfm3XffNbfddptJS0szXq/3K1/b2tpqJLGxsbGxRfnW2tr6pV/v44yJ/MNIi4qKNH36dP3mN7+R9OlVTU5OjlasWKF77rnnS1/r8/mUlpam2fofJSgx0qMBAIbYafXoNf2v2tvb5XQ6+z0v4t+C6+7uVmNjoyorK4P74uPjVVxcrPr6+rPODwQCCgQCwY87Ojr+f7BEJcQRIACIOv9/WfNVP0aJ+E0IH330kc6cOSOXyxWy3+VyyePxnHV+VVWVnE5ncMvJyYn0SACAYcj6XXCVlZXy+XzBrbW11fZIAIBzIOLfgrvooot0wQUXyOv1huz3er3KzMw863yHwyGHwxHpMQAAw1zEr4CSkpJUWFio2tra4L7e3l7V1tbK7XZH+tMBAKLUkPweUEVFhRYvXqxp06ZpxowZWr9+vTo7O3XrrbcOxacDAEShIQnQwoUL9a9//UurV6+Wx+PRlVdeqb179551YwIA4Pw1JL8HNBh+v19Op1PXqJTbsAEgCp02PdqvXfL5fEpNTe33POt3wQEAzk8ECABgBQECAFhBgAAAVhAgAIAVBAgAYAUBAgBYQYAAAFYQIACAFQQIAGAFAQIAWEGAAABWECAAgBUECABgBQECAFhBgAAAVhAgAIAVBAgAYAUBAgBYQYAAAFYQIACAFQQIAGAFAQIAWEGAAABWECAAgBUECABgBQECAFhBgAAAVhAgAIAVBAgAYAUBAgBYQYAAAFYQIACAFQQIAGAFAQIAWEGAAABWECAAgBUECABgBQECAFhBgAAAVhAgAIAVBAgAYAUBAgBYQYAAAFYQIACAFQQIAGAFAQIAWBF2gF599VVdf/31ys7OVlxcnHbu3Bly3Bij1atXKysrS8nJySouLtaxY8ciNS+A88y+tsN9boh+YQeos7NTU6ZM0caNG/s8/tBDD2nDhg3avHmzGhoaNHLkSJWUlKirq2vQwwIAYkdCuC+YN2+e5s2b1+cxY4zWr1+ve++9V6WlpZKkZ599Vi6XSzt37tRNN9101msCgYACgUDwY7/fH+5IAIAoFNGfATU3N8vj8ai4uDi4z+l0qqioSPX19X2+pqqqSk6nM7jl5OREciQAwDAV0QB5PB5JksvlCtnvcrmCx76osrJSPp8vuLW2tkZyJADAMBX2t+AizeFwyOFw2B4DAHCORfQKKDMzU5Lk9XpD9nu93uAxAACkCAcoLy9PmZmZqq2tDe7z+/1qaGiQ2+2O5KcCAES5sL8Fd+rUKR0/fjz4cXNzsw4fPqz09HTl5uZq5cqVeuCBBzRhwgTl5eXpvvvuU3Z2tubPnx/JuQEAUS7sAB06dEjf/e53gx9XVFRIkhYvXqytW7fqrrvuUmdnp5YuXar29nbNnj1be/fu1YgRIyI3NQAg6sUZY4ztIT7P7/fL6XTqGpUqIS7R9jgALOvvqQcl2Vee0znw9Z02PdqvXfL5fEpNTe33POt3wQHAQBCm6MfDSAEAVhAgAIAVBAgAYAUBAgBYQYAAAFZwFxyAqMTdbtGPKyAAgBUECABgBQECAFhBgAAAVhAgAIAV3AUHYFjjbrfYxRUQAMAKAgQAsIIAAQCsIEAAACsIEADACgIEALCCAAEArCBAAAArCBAAwAoCBACwggABAKwgQAAAKwgQAMAKAgQAsIIAAQCsIEAAACsIEADACgIEALCCAAEArCBAAAArCBAAwAoCBACwIsH2AAAQ7fa1HT5rX0n2led8jmjDFRAAwAoCBACwggABAKwgQAAAKwgQAMAKAgQAsIIAAQCsIEAAACsIEADACgIEALAirABVVVVp+vTpGjVqlMaOHav58+erqakp5Jyuri6Vl5crIyNDKSkpKisrk9frjejQAIDoF9az4Orq6lReXq7p06fr9OnT+vnPf65rr71WR48e1ciRIyVJq1at0p///Gdt375dTqdTy5cv14IFC/T6668PyQIAYDjq6/lwEs+I+7ywArR3796Qj7du3aqxY8eqsbFR3/72t+Xz+fT0009r27ZtmjNnjiRpy5Ytmjhxog4cOKCZM2dGbnIAQFQb1M+AfD6fJCk9PV2S1NjYqJ6eHhUXFwfPyc/PV25ururr6/t8j0AgIL/fH7IBAGLfgAPU29urlStXatasWZo8ebIkyePxKCkpSWlpaSHnulwueTyePt+nqqpKTqczuOXk5Ax0JABAFBlwgMrLy/XOO++opqZmUANUVlbK5/MFt9bW1kG9HwAgOgzoD9ItX75cL774ol599VWNGzcuuD8zM1Pd3d1qb28PuQryer3KzMzs870cDoccDsdAxgAARLGwroCMMVq+fLl27Nihl19+WXl5eSHHCwsLlZiYqNra2uC+pqYmtbS0yO12R2ZiAEBMCOsKqLy8XNu2bdOuXbs0atSo4M91nE6nkpOT5XQ6tWTJElVUVCg9PV2pqalasWKF3G43d8ABAEKEFaDq6mpJ0jXXXBOyf8uWLfrRj34kSVq3bp3i4+NVVlamQCCgkpISbdq0KSLDAgBiR1gBMsZ85TkjRozQxo0btXHjxgEPBQCIfTwLDgBgBQECAFhBgAAAVhAgAIAVBAgAYAUBAgBYQYAAAFYM6FlwAID/6uuPzPX3B+nwX1wBAQCsIEAAACsIEADACgIEALCCAAEArCBAAAArCBAAwAoCBACwggABAKwgQAAAKwgQAMAKngUHAOdQf8+I6+t5crGOKyAAgBUECABgBQECAFhBgAAAVhAgAIAVBAgAYAUBAgBYQYAAAFYQIACAFQQIAGAFAQIAWEGAAABWECAAgBUECABgBQECAFhBgAAAVhAgAIAVBAgAYAUBAgBYQYAAAFYQIACAFQQIAGAFAQIAWEGAAABWECAAgBUECABgBQECAFgRVoCqq6tVUFCg1NRUpaamyu12a8+ePcHjXV1dKi8vV0ZGhlJSUlRWViav1xvxoQEA0S+sAI0bN05r165VY2OjDh06pDlz5qi0tFTvvvuuJGnVqlXavXu3tm/frrq6OrW1tWnBggVDMjgAILrFGWPMYN4gPT1dDz/8sG644QaNGTNG27Zt0w033CBJ+vvf/66JEyeqvr5eM2fO/Frv5/f75XQ6dY1KlRCXOJjRAMCafW2Hwzq/JPvKIZnDhtOmR/u1Sz6fT6mpqf2eN+CfAZ05c0Y1NTXq7OyU2+1WY2Ojenp6VFxcHDwnPz9fubm5qq+v7/d9AoGA/H5/yAYAiH1hB+jIkSNKSUmRw+HQ7bffrh07dmjSpEnyeDxKSkpSWlpayPkul0sej6ff96uqqpLT6QxuOTk5YS8CABB9wg7QZZddpsOHD6uhoUHLli3T4sWLdfTo0QEPUFlZKZ/PF9xaW1sH/F4AgOiREO4LkpKSdMkll0iSCgsLdfDgQT322GNauHChuru71d7eHnIV5PV6lZmZ2e/7ORwOORyO8CcHAES1Qf8eUG9vrwKBgAoLC5WYmKja2trgsaamJrW0tMjtdg/20wAAYkxYV0CVlZWaN2+ecnNz1dHRoW3btmn//v3at2+fnE6nlixZooqKCqWnpys1NVUrVqyQ2+3+2nfAAQDOH2EF6OTJk/rhD3+oEydOyOl0qqCgQPv27dP3vvc9SdK6desUHx+vsrIyBQIBlZSUaNOmTUMyOAAgug3694Aijd8DAhAL+D2gIfw9IAAABoMAAQCsIEAAACsIEADACgIEALCCAAEArCBAAAArCBAAwAoCBACwggABAKwgQAAAKwgQAMAKAgQAsCLsv4gKAPhq/T3dOtynZMcyroAAAFYQIACAFQQIAGAFAQIAWMFNCABwDsXSn94eLK6AAABWECAAgBUECABgBQECAFhBgAAAVnAXHIBzrq/H0XB32PmHKyAAgBUECABgBQECAFhBgAAAVhAgAIAVBAgAYAUBAgBYQYAAAFYQIACAFQQIAGAFAQIAWMGz4AAMmb6e+QZ8hisgAIAVBAgAYAUBAgBYQYAAAFYQIACAFQQIAGAFAQIAWEGAAABWECAAgBUECABgxaACtHbtWsXFxWnlypXBfV1dXSovL1dGRoZSUlJUVlYmr9c72DkBADFmwAE6ePCgnnjiCRUUFITsX7VqlXbv3q3t27errq5ObW1tWrBgwaAHBQDElgEF6NSpU1q0aJGeeuopjR49Orjf5/Pp6aef1qOPPqo5c+aosLBQW7Zs0V//+lcdOHAgYkMDAKLfgAJUXl6u6667TsXFxSH7Gxsb1dPTE7I/Pz9fubm5qq+v7/O9AoGA/H5/yAYAiH1h/zmGmpoavfnmmzp48OBZxzwej5KSkpSWlhay3+VyyePx9Pl+VVVV+sUvfhHuGACAKBfWFVBra6vuvPNOPffccxoxYkREBqisrJTP5wtura2tEXlfAMDwFlaAGhsbdfLkSV111VVKSEhQQkKC6urqtGHDBiUkJMjlcqm7u1vt7e0hr/N6vcrMzOzzPR0Oh1JTU0M2AEDsC+tbcHPnztWRI0dC9t16663Kz8/X3XffrZycHCUmJqq2tlZlZWWSpKamJrW0tMjtdkduagBA1AsrQKNGjdLkyZND9o0cOVIZGRnB/UuWLFFFRYXS09OVmpqqFStWyO12a+bMmZGbGgAQ9cK+CeGrrFu3TvHx8SorK1MgEFBJSYk2bdoU6U8DAIhyccYYY3uIz/P7/XI6nbpGpUqIS7Q9DoBB2Nd2+GufW5J95ZDNgXPrtOnRfu2Sz+f70p/r8yw4AIAVBAgAYAUBAgBYQYAAAFYQIACAFQQIAGAFAQIAWEGAAABWECAAgBUECABgBQECAFhBgAAAVkT8adgA8Jn+HjAazkNKEbu4AgIAWEGAAABWECAAgBUECABgBQECAFhBgAAAVhAgAIAVBAgAYAUBAgBYQYAAAFYQIACAFTwLDsA5198z4nB+4QoIAGAFAQIAWEGAAABWECAAgBUECABgBQECAFhBgAAAVhAgAIAVBAgAYAUBAgBYQYAAAFYQIACAFQQIAGAFAQIAWEGAAABWECAAgBUECABgBQECAFhBgAAAVhAgAIAVBAgAYAUBAgBYEVaA7r//fsXFxYVs+fn5weNdXV0qLy9XRkaGUlJSVFZWJq/XG/GhAQDRL+wroMsvv1wnTpwIbq+99lrw2KpVq7R7925t375ddXV1amtr04IFCyI6MAAgNiSE/YKEBGVmZp613+fz6emnn9a2bds0Z84cSdKWLVs0ceJEHThwQDNnzuzz/QKBgAKBQPBjv98f7kgAgCgU9hXQsWPHlJ2drYsvvliLFi1SS0uLJKmxsVE9PT0qLi4Onpufn6/c3FzV19f3+35VVVVyOp3BLScnZwDLAABEm7ACVFRUpK1bt2rv3r2qrq5Wc3Ozrr76anV0dMjj8SgpKUlpaWkhr3G5XPJ4PP2+Z2VlpXw+X3BrbW0d0EIAANElrG/BzZs3L/jvgoICFRUVafz48Xr++eeVnJw8oAEcDoccDseAXgsAiF6Dug07LS1Nl156qY4fP67MzEx1d3ervb095Byv19vnz4wAAOe3QQXo1KlTev/995WVlaXCwkIlJiaqtrY2eLypqUktLS1yu92DHhQAEFvC+hbcz372M11//fUaP3682tratGbNGl1wwQW6+eab5XQ6tWTJElVUVCg9PV2pqalasWKF3G53v3fAAQDOX2EF6J///Kduvvlm/fvf/9aYMWM0e/ZsHThwQGPGjJEkrVu3TvHx8SorK1MgEFBJSYk2bdo0JIMDAKJbnDHG2B7i8/x+v5xOp65RqRLiEm2PAwAI02nTo/3aJZ/Pp9TU1H7P41lwAAArCBAAwAoCBACwggABAKwgQAAAKwgQAMAKAgQAsIIAAQCsIEAAACsIEADACgIEALCCAAEArCBAAAArCBAAwAoCBACwggABAKwgQAAAKwgQAMAKAgQAsIIAAQCsIEAAACsIEADACgIEALCCAAEArCBAAAArCBAAwAoCBACwggABAKwgQAAAKwgQAMAKAgQAsIIAAQCsIEAAACsIEADACgIEALCCAAEArCBAAAArCBAAwAoCBACwggABAKwgQAAAKwgQAMAKAgQAsIIAAQCsIEAAACsIEADAirAD9OGHH+qWW25RRkaGkpOTdcUVV+jQoUPB48YYrV69WllZWUpOTlZxcbGOHTsW0aEBANEvrAB9/PHHmjVrlhITE7Vnzx4dPXpUjzzyiEaPHh0856GHHtKGDRu0efNmNTQ0aOTIkSopKVFXV1fEhwcARK+EcE7+9a9/rZycHG3ZsiW4Ly8vL/hvY4zWr1+ve++9V6WlpZKkZ599Vi6XSzt37tRNN90UobEBANEurCugF154QdOmTdONN96osWPHaurUqXrqqaeCx5ubm+XxeFRcXBzc53Q6VVRUpPr6+j7fMxAIyO/3h2wAgNgXVoA++OADVVdXa8KECdq3b5+WLVumO+64Q88884wkyePxSJJcLlfI61wuV/DYF1VVVcnpdAa3nJycgawDABBlwgpQb2+vrrrqKj344IOaOnWqli5dqttuu02bN28e8ACVlZXy+XzBrbW1dcDvBQCIHmEFKCsrS5MmTQrZN3HiRLW0tEiSMjMzJUlerzfkHK/XGzz2RQ6HQ6mpqSEbACD2hRWgWbNmqampKWTfe++9p/Hjx0v69IaEzMxM1dbWBo/7/X41NDTI7XZHYFwAQKwI6y64VatW6Vvf+pYefPBB/eAHP9Abb7yhJ598Uk8++aQkKS4uTitXrtQDDzygCRMmKC8vT/fdd5+ys7M1f/78oZgfABClwgrQ9OnTtWPHDlVWVuqXv/yl8vLytH79ei1atCh4zl133aXOzk4tXbpU7e3tmj17tvbu3asRI0ZEfHgAQPSKM8YY20N8nt/vl9Pp1DUqVUJcou1xAABhOm16tF+75PP5vvTn+jwLDgBgBQECAFhBgAAAVhAgAIAVBAgAYAUBAgBYQYAAAFYQIACAFQQIAGAFAQIAWEGAAABWECAAgBVhPQ37XPjs2ain1SMNq8ekAgC+jtPqkfTfr+f9GXYB6ujokCS9pv+1PAkAYDA6OjrkdDr7PT7s/hxDb2+v2traNGrUKHV0dCgnJ0etra0x/ae6/X4/64wR58MaJdYZayK9TmOMOjo6lJ2drfj4/n/SM+yugOLj4zVu3DhJn/6FVUlKTU2N6f/8z7DO2HE+rFFinbEmkuv8siufz3ATAgDACgIEALBiWAfI4XBozZo1cjgctkcZUqwzdpwPa5RYZ6yxtc5hdxMCAOD8MKyvgAAAsYsAAQCsIEAAACsIEADACgIEALBiWAdo48aN+uY3v6kRI0aoqKhIb7zxhu2RBuXVV1/V9ddfr+zsbMXFxWnnzp0hx40xWr16tbKyspScnKzi4mIdO3bMzrADVFVVpenTp2vUqFEaO3as5s+fr6amppBzurq6VF5eroyMDKWkpKisrExer9fSxANTXV2tgoKC4G+Ou91u7dmzJ3g8Ftb4RWvXrlVcXJxWrlwZ3BcL67z//vsVFxcXsuXn5wePx8IaP/Phhx/qlltuUUZGhpKTk3XFFVfo0KFDwePn+mvQsA3QH//4R1VUVGjNmjV68803NWXKFJWUlOjkyZO2Rxuwzs5OTZkyRRs3buzz+EMPPaQNGzZo8+bNamho0MiRI1VSUqKurq5zPOnA1dXVqby8XAcOHNBLL72knp4eXXvtters7Ayes2rVKu3evVvbt29XXV2d2tratGDBAotTh2/cuHFau3atGhsbdejQIc2ZM0elpaV69913JcXGGj/v4MGDeuKJJ1RQUBCyP1bWefnll+vEiRPB7bXXXgsei5U1fvzxx5o1a5YSExO1Z88eHT16VI888ohGjx4dPOecfw0yw9SMGTNMeXl58OMzZ86Y7OxsU1VVZXGqyJFkduzYEfy4t7fXZGZmmocffji4r7293TgcDvOHP/zBwoSRcfLkSSPJ1NXVGWM+XVNiYqLZvn178Jy//e1vRpKpr6+3NWZEjB492vz2t7+NuTV2dHSYCRMmmJdeesl85zvfMXfeeacxJnb+L9esWWOmTJnS57FYWaMxxtx9991m9uzZ/R638TVoWF4BdXd3q7GxUcXFxcF98fHxKi4uVn19vcXJhk5zc7M8Hk/Imp1Op4qKiqJ6zT6fT5KUnp4uSWpsbFRPT0/IOvPz85Wbmxu16zxz5oxqamrU2dkpt9sdc2ssLy/XddddF7IeKbb+L48dO6bs7GxdfPHFWrRokVpaWiTF1hpfeOEFTZs2TTfeeKPGjh2rqVOn6qmnngoet/E1aFgG6KOPPtKZM2fkcrlC9rtcLnk8HktTDa3P1hVLa+7t7dXKlSs1a9YsTZ48WdKn60xKSlJaWlrIudG4ziNHjiglJUUOh0O33367duzYoUmTJsXUGmtqavTmm2+qqqrqrGOxss6ioiJt3bpVe/fuVXV1tZqbm3X11Vero6MjZtYoSR988IGqq6s1YcIE7du3T8uWLdMdd9yhZ555RpKdr0HD7s8xIHaUl5frnXfeCfl+eiy57LLLdPjwYfl8Pv3pT3/S4sWLVVdXZ3usiGltbdWdd96pl156SSNGjLA9zpCZN29e8N8FBQUqKirS+PHj9fzzzys5OdniZJHV29uradOm6cEHH5QkTZ06Ve+88442b96sxYsXW5lpWF4BXXTRRbrgggvOutPE6/UqMzPT0lRD67N1xcqaly9frhdffFGvvPJK8O87SZ+us7u7W+3t7SHnR+M6k5KSdMkll6iwsFBVVVWaMmWKHnvssZhZY2Njo06ePKmrrrpKCQkJSkhIUF1dnTZs2KCEhAS5XK6YWOcXpaWl6dJLL9Xx48dj5v9SkrKysjRp0qSQfRMnTgx+u9HG16BhGaCkpCQVFhaqtrY2uK+3t1e1tbVyu90WJxs6eXl5yszMDFmz3+9XQ0NDVK3ZGKPly5drx44devnll5WXlxdyvLCwUImJiSHrbGpqUktLS1Stsy+9vb0KBAIxs8a5c+fqyJEjOnz4cHCbNm2aFi1aFPx3LKzzi06dOqX3339fWVlZMfN/KUmzZs0661ci3nvvPY0fP16Spa9BQ3JrQwTU1NQYh8Nhtm7dao4ePWqWLl1q0tLSjMfjsT3agHV0dJi33nrLvPXWW0aSefTRR81bb71l/vGPfxhjjFm7dq1JS0szu3btMm+//bYpLS01eXl55pNPPrE8+de3bNky43Q6zf79+82JEyeC23/+85/gObfffrvJzc01L7/8sjl06JBxu93G7XZbnDp899xzj6mrqzPNzc3m7bffNvfcc4+Ji4szf/nLX4wxsbHGvnz+LjhjYmOdP/3pT83+/ftNc3Ozef31101xcbG56KKLzMmTJ40xsbFGY4x54403TEJCgvnVr35ljh07Zp577jlz4YUXmt///vfBc87116BhGyBjjHn88cdNbm6uSUpKMjNmzDAHDhywPdKgvPLKK0bSWdvixYuNMZ/eBnnfffcZl8tlHA6HmTt3rmlqarI7dJj6Wp8ks2XLluA5n3zyifnJT35iRo8ebS688ELz/e9/35w4ccLe0APw4x//2IwfP94kJSWZMWPGmLlz5wbjY0xsrLEvXwxQLKxz4cKFJisryyQlJZlvfOMbZuHCheb48ePB47Gwxs/s3r3bTJ482TgcDpOfn2+efPLJkOPn+msQfw8IAGDFsPwZEAAg9hEgAIAVBAgAYAUBAgBYQYAAAFYQIACAFQQIAGAFAQIAWEGAAABWECAAgBUECABgxf8BhQcXA/cH17gAAAAASUVORK5CYII=\n"},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"wWjDQiyaX29j"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30823,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}